# -*- coding: utf-8 -*-
"""CNN1D - Yes/No recognition MFCCS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AXIN3F4HCPWCLD9S2_PK62d6-NGF4kim
"""

!pip uninstall -y scikit-learn
!pip uninstall -y pandas
!pip uninstall -y pandas_ml

!pip install scikit-learn==0.20.0
!pip install pandas==0.24.0
!pip install pandas_ml

!pip install --upgrade wandb
!wandb login 3192017bec404c8c4f881ace5da7c4d4debf8b93

# Commented out IPython magic to ensure Python compatibility.
try:
  # Use the %tensorflow_version magic if in colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

import os

import numpy as np

import librosa
import librosa.display as dsp

import pandas as pd
import pandas_ml

from tensorflow.python.keras import Sequential
from keras import Input
from keras.engine import Model
from keras.utils import to_categorical
from keras.layers import TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, \
    LSTM, Flatten, RepeatVector, Permute, Multiply, Conv1D, MaxPooling1D, Dense

from sklearn.model_selection import train_test_split

import wandb
from wandb.keras import WandbCallback

!git clone https://github.com/julianmangut/tfg_speech_commands.git

DATA_DIR_GENERAL = 'tfg_speech_commands/audios/'

folder_list = os.listdir(DATA_DIR_GENERAL)

"""**Preprocesamiento**"""

def extract_features_mfccs(wav, sample_rate):
  mfccs = librosa.feature.mfcc(y=wav, sr=sample_rate, n_mfcc=40)
  mfccs_processed = np.mean(mfccs.T, axis=0)

  return mfccs_processed

features_mfccs = []
digit = []

for folder_name in folder_list:
  DIR_FOLDER = DATA_DIR_GENERAL + folder_name + '/'
  print(DIR_FOLDER)
  if(folder_name == 'no'):
    number = 0
  else:
    number = 1
  for fname in os.listdir(DIR_FOLDER):
    if '.wav' not in fname:
      continue

    audio, sample_rate = librosa.load(DIR_FOLDER + fname, sr=None, res_type='kaiser_fast')

    data_mfccs = extract_features_mfccs(audio, sample_rate)

    features_mfccs.append(data_mfccs)
    digit.append(number)

#features_Panda_mfccs = pd.DataFrame(features_mfccs, columns=['feature_mfccs', 'audio_info'])

X_mfccs = np.array(features_mfccs)

yy = to_categorical(np.array(digit))

x_train_mfccs, x_test_mfccs, y_train_mfccs, y_test_mfccs = train_test_split(features_mfccs, yy, test_size=0.2, random_state = 127)
x_train_mfccs = np.array(x_train_mfccs)
print("X_train shape : ", x_train_mfccs.shape)
#print("X_test shape : ", x_test_mfccs.shape)

x_validation_mfccs, x_test_mfccs, y_validation_mfccs, y_test_mfccs = train_test_split(x_test_mfccs, y_test_mfccs, test_size=0.5, random_state=80)
x_validation_mfccs = np.array(x_validation_mfccs)
x_test_mfccs = np.array(x_test_mfccs)
print("X_test shape : ", x_test_mfccs.shape)
print("X_validation shape : ",x_validation_mfccs.shape)

train_X_ex = np.expand_dims(x_train_mfccs, -1)
validation_X_ex = np.expand_dims(x_validation_mfccs, -1)
test_X_ex = np.expand_dims(x_test_mfccs, -1)
print ('train X shape:', train_X_ex.shape)
print('validation X shape:', validation_X_ex.shape)
print ('test X shape:', test_X_ex.shape)

"""**Modelo y entrenamiento**"""

num_labels = yy.shape[1]
model_mfccs = tf.keras.Sequential([
                             tf.keras.layers.Input(shape=train_X_ex[0].shape),


                             #tf.keras.layers.GaussianNoise(0.01, input_shape=(train_X_ex[0].shape)),

                             

                             tf.keras.layers.Conv1D(64,4, activation='relu'),
                             tf.keras.layers.MaxPooling1D(pool_size=2),
                             tf.keras.layers.Dropout(0.4),

                             tf.keras.layers.Conv1D(128,4, activation='relu'),
                             tf.keras.layers.MaxPooling1D(pool_size=2),
                             tf.keras.layers.Dropout(0.4),

                             #tf.keras.layers.Conv1D(64, kernel_size=(4), activation='relu'),
                             #tf.keras.layers.MaxPooling1D(pool_size=(2)),
                             #tf.keras.layers.Dropout(0.2),

                            #  tf.keras.layers.Conv2D(128, kernel_size=(2, 2), activation='relu'),
                            #  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
                            #  tf.keras.layers.Dropout(0.2),

                             #tf.keras.layers.Flatten(),
                             #tf.keras.layers.Dense(256, activation='relu'),
                             #tf.keras.layers.Dropout(0.3),

                             #tf.keras.layers.Dense(128, activation='relu'),
                             #tf.keras.layers.Dropout(0.3),
                             tf.keras.layers.GlobalAveragePooling1D(),
                             tf.keras.layers.Dense(num_labels, activation='softmax')

                            # tf.keras.layers.Conv2D(filters=16, kernel_size=2, input_shape=train_X_ex[0].shape, activation='relu'),
                            # tf.keras.layers.MaxPooling2D(pool_size=2),
                            # tf.keras.layers.Dropout(0.2),

                            # tf.keras.layers.Conv2D(filters=32, kernel_size=2, activation='relu'),
                            # tf.keras.layers.MaxPooling2D(pool_size=2),
                            # tf.keras.layers.Dropout(0.2),

                            # tf.keras.layers.Conv2D(filters=64, kernel_size=2, activation='relu'),
                            # tf.keras.layers.MaxPooling2D(pool_size=2),
                            # tf.keras.layers.Dropout(0.2),

                            # tf.keras.layers.Conv2D(filters=128, kernel_size=2, activation='relu'),
                            # tf.keras.layers.MaxPooling2D(pool_size=2),
                            # tf.keras.layers.Dropout(0.2),
                            # tf.keras.layers.GlobalAveragePooling2D(),

                            # tf.keras.layers.Dense(10, activation='softmax')
])

model_mfccs.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

model_mfccs.summary()

score = model_mfccs.evaluate(test_X_ex, y_test_mfccs, verbose=0)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

num_epochs = 100
num_batch_size = 32

wandb.init(project="tfg")

history = model_mfccs.fit(train_X_ex, y_train_mfccs, batch_size=num_batch_size, epochs=num_epochs, validation_data=(validation_X_ex, y_validation_mfccs), verbose=1, callbacks=[WandbCallback()])

score = model_mfccs.evaluate(train_X_ex, y_train_mfccs, verbose=0)
print("Training Accuracy: {0:.2%}".format(score[1]))

score = model_mfccs.evaluate(test_X_ex, y_test_mfccs, verbose=0)
print("Testing Accuracy: {0:.2%}".format(score[1]))